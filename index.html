<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Video Semantic Object Segmentation by Self-Adaptation of DCNN by SeongjinPark</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Video Semantic Object Segmentation by Self-Adaptation of DCNN</h1>
      <h2 class="project-tagline">Seong-Jin Park <span style="width:70px;display:inline-block"></span> Ki-Sang Hong</h2>
     <h2 class="project-tagline">POSTECH</h2>

<!--      <a href="https://github.com/SeongjinPark/AdaptNet" class="btn">View on GitHub</a> -->
      <a href="http://vision.cs.utexas.edu/projects/videoseg/data_download_register.html" class="btn">Download dataset2014.zip</a>  
      <a href="https://github.com/SeongjinPark/AdaptNet/zipball/master" class="btn">Download dataset2014_new.zip</a>
      <a href="https://github.com/SeongjinPark/AdaptNet/zipball/master" class="btn">Download dataset2015.zip</a>
    </section>

    <section class="main-content">
      <h3>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h3>

<p>This paper proposes a new framework for semantic segmentation of objects in videos. We address the label inconsistency problem of deep convolutional neural networks (DCNNs) by exploiting the fact that videos have multiple frames; in a few frames the object is confidently-estimated (CE) and we use the information in them to improve labels of the other frames. Given the semantic segmentation results of each frame obtained from DCNN, we sample several CE frames to adapt the DCNN model to the input video by focusing on specific instances in the video rather than general objects in various circumstances. We propose offline and online approaches under different supervision levels. In experiments our method achieved great improvement over the original model and previous state-of-the-art methods.</p>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h3>
<p>Representative results of the proposed method compared with the baseline model. <br>Top: Base-front-end, Middle: Our-Weak-comb, Bottom: Our-Weak-comb-CRF.</p>
<p><img src="http://iip.postech.ac.kr/img/results.PNG" alt="results"></p>


<h3>
<a id="Videos" class="anchor" href="#Videos" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Videos</h3>
<p>Comparison between the results of the baseline model (left) and ours (right). 

<p><embed src = "https://drive.google.com/file/d/0B5UJHuz4PAWEMnJGVlp5MXdrUkE/view?usp=sharing" width="700px"></embed></p>  
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/5_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/3_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/1_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/10_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/1222_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/111111_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/113_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/116_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/1111_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/1115_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/1117_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/1119_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/7_compare_g.mp4" width="700px" controls></video></p> 
<p><video src = "http://iip.postech.ac.kr/img/results_color_video_sampled/9_compare_g.mp4" width="700px" controls></video></p> 
  
<h3>
<a id="Paper" class="anchor" href="#Paper" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Paper</h3>
<p>under review...</p>

<h3>
<a id="Contact" class="anchor" href="#Contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h3>

<p><a href="windray@postech.ac.kr">windray@postech.ac.kr</a></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/SeongjinPark/AdaptNet">Video Semantic Object Segmentation by Self-Adaptation of DCNN</a> is maintained by <a href="https://github.com/SeongjinPark">SeongjinPark</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
